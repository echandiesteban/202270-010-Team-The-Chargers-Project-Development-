{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPclFb7LB/KzuOOfyWfdIWc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/echandiesteban/202270-010-Team-The-Chargers-Project-Development-/blob/main/WordVec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkbkt252P2lA",
        "outputId": "e3aa6144-a9d1-49e2-d5e1-b2a0cab958e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[K     |████████████████████████████████| 275 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lime) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lime) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lime) (4.64.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from lime) (1.0.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime) (0.18.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (1.3.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.9.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.6.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->lime) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->lime) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (3.1.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283857 sha256=a31c06bc15fb8de33145c641105a84714073b1cf1441fb9bfb8a83e57dc874d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/cb/e5/ac701e12d365a08917bf4c6171c0961bc880a8181359c66aa7\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install lime\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "## for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "## for processing\n",
        "import re\n",
        "import nltk\n",
        "## for bag-of-words\n",
        "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing\n",
        "## for explainer\n",
        "from lime import lime_text\n",
        "## for word embedding\n",
        "import gensim\n",
        "import gensim.downloader as gensim_api"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## for deep learning\n",
        "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
        "from tensorflow.keras import backend as K\n",
        "## for bert language model\n",
        "\n",
        "!pip install transformers\n",
        "import transformers"
      ],
      "metadata": {
        "id": "BTo6F1mKQOae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "id": "xmLGwZ4rQVNW",
        "outputId": "4915c0fc-9d15-4320-c8b3-60f14d4393a8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a09ced04-8ce7-4121-883a-4be89c2bc719\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a09ced04-8ce7-4121-883a-4be89c2bc719\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving SOPsv1Googlecolab.csv to SOPsv1Googlecolab.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "dtf = pd.read_csv(io.BytesIO(uploaded['SOPsv1Googlecolab.csv']))\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ],
      "metadata": {
        "id": "y7Ot2IJkQcKZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "lst_stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "lst_stopwords\n",
        "\n",
        "dtf[\"text_clean\"] = dtf[\"text\"]\n",
        "dtf.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "325AyzZBQfx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = gensim_api.load(\"glove-wiki-gigaword-100\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXcaCq-uSu6p",
        "outputId": "a4ab5afb-4687-48e4-de2a-97005d2ae103"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtf[\"text_clean\"] = dtf[\"text\"]\n",
        "dtf.head()\n",
        "\n",
        "## split dataset\n",
        "dtf_train, dtf_test = model_selection.train_test_split(dtf, test_size=0.3)\n",
        "## get target\n",
        "y_train = dtf_train[\"y\"].values\n",
        "y_test = dtf_test[\"y\"].values"
      ],
      "metadata": {
        "id": "TLYckexMTg9X"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = dtf_train[\"text_clean\"]\n",
        "\n",
        "## create list of lists of unigrams\n",
        "lst_corpus = []\n",
        "for string in corpus:\n",
        "   lst_words = string.split()\n",
        "   lst_grams = [\" \".join(lst_words[i:i+1]) \n",
        "               for i in range(0, len(lst_words), 1)]\n",
        "   lst_corpus.append(lst_grams)\n",
        "\n",
        "## detect bigrams and trigrams\n",
        "bigrams_detector = gensim.models.phrases.Phrases(lst_corpus, \n",
        "                 delimiter=\" \".encode(), min_count=5, threshold=10)\n",
        "bigrams_detector = gensim.models.phrases.Phraser(bigrams_detector)\n",
        "trigrams_detector = gensim.models.phrases.Phrases(bigrams_detector[lst_corpus], \n",
        "            delimiter=\" \".encode(), min_count=5, threshold=10)\n",
        "trigrams_detector = gensim.models.phrases.Phraser(trigrams_detector)"
      ],
      "metadata": {
        "id": "r-YlXwykTojD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## fit w2v\n",
        "nlp = gensim.models.word2vec.Word2Vec(lst_corpus, size=300,   \n",
        "            window=8, min_count=1, sg=1, iter=30)"
      ],
      "metadata": {
        "id": "T09Oc_1xTqqM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"data\"\n",
        "nlp[word].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUvtMJlrTvb5",
        "outputId": "1d085347-d5d4-4496-ebe8-c6c949aaf747"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"data\"\n",
        "fig = plt.figure()\n",
        "## word embedding\n",
        "tot_words = [word] + [tupla[0] for tupla in \n",
        "                 nlp.most_similar(word, topn=20)]\n",
        "X = nlp[tot_words]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "BhyiNF5FT0BU",
        "outputId": "6eeefdbc-2979-4e83-ef6a-d958e0b82d6e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## pca to reduce dimensionality from 300 to 3\n",
        "pca = manifold.TSNE(perplexity=40, n_components=3, init='pca')\n",
        "X = pca.fit_transform(X)\n",
        "## create dtf\n",
        "dtf_ = pd.DataFrame(X, index=tot_words, columns=[\"x\",\"y\",\"z\"])\n",
        "dtf_[\"input\"] = 0\n",
        "dtf_[\"input\"].iloc[0:1] = 1\n",
        "## plot 3d\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(dtf_[dtf_[\"input\"]==0]['x'], \n",
        "           dtf_[dtf_[\"input\"]==0]['y'], \n",
        "           dtf_[dtf_[\"input\"]==0]['z'], c=\"black\")\n",
        "ax.scatter(dtf_[dtf_[\"input\"]==1]['x'], \n",
        "           dtf_[dtf_[\"input\"]==1]['y'], \n",
        "           dtf_[dtf_[\"input\"]==1]['z'], c=\"red\")\n",
        "ax.set(xlabel=None, ylabel=None, zlabel=None, xticklabels=[], \n",
        "       yticklabels=[], zticklabels=[])\n",
        "for label, row in dtf_[[\"x\",\"y\",\"z\"]].iterrows():\n",
        "    x, y, z = row\n",
        "    ax.text(x, y, z, s=label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31kb0mxCT7cc",
        "outputId": "e7faeb08-5322-40f9-931e-625f5f9ce0e1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## tokenize text\n",
        "tokenizer = kprocessing.text.Tokenizer(lower=True, split=' ', \n",
        "                     oov_token=\"NaN\", \n",
        "                     filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "tokenizer.fit_on_texts(lst_corpus)\n",
        "dic_vocabulary = tokenizer.word_index\n",
        "## create sequence\n",
        "lst_text2seq= tokenizer.texts_to_sequences(lst_corpus)\n",
        "## padding sequence\n",
        "X_train = kprocessing.sequence.pad_sequences(lst_text2seq, \n",
        "                    maxlen=15, padding=\"post\", truncating=\"post\")"
      ],
      "metadata": {
        "id": "YyklNz3nUCgL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(X_train==0, vmin=0, vmax=1, cbar=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "Y8P7UGCxUHzp",
        "outputId": "c73c9e31-37c9-42c8-e439-141397da8425"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "\n",
        "## list of text: [\"I like this\", ...]\n",
        "len_txt = len(dtf_train[\"text_clean\"].iloc[i].split())\n",
        "print(\"from: \", dtf_train[\"text_clean\"].iloc[i], \"| len:\", len_txt)\n",
        "\n",
        "## sequence of token ids: [[1, 2, 3], ...]\n",
        "len_tokens = len(X_train[i])\n",
        "print(\"to: \", X_train[i], \"| len:\", len(X_train[i]))\n",
        "\n",
        "## vocabulary: {\"I\":1, \"like\":2, \"this\":3, ...}\n",
        "print(\"check: \", dtf_train[\"text_clean\"].iloc[i].split()[0], \n",
        "      \" -- idx in vocabulary -->\", \n",
        "      dic_vocabulary[dtf_train[\"text_clean\"].iloc[i].split()[0]])\n",
        "\n",
        "print(\"vocabulary: \", dict(list(dic_vocabulary.items())[0:5]), \"... (padding element, 0)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_xl9c4EUMRg",
        "outputId": "670c980c-9bf3-4078-d65e-89fa445f2598"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from:  before descending below Minimum Descent Attitude Eight | len: 7\n",
            "to:  [ 53 123  56  34  20   9  68   0   0   0   0   0   0   0   0] | len: 15\n",
            "check:  before  -- idx in vocabulary --> 53\n",
            "vocabulary:  {'NaN': 1, 'the': 2, 'takeoff': 3, 'and': 4, 'on': 5} ... (padding element, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = dtf_test[\"text_clean\"]\n",
        "\n",
        "## create list of n-grams\n",
        "lst_corpus = []\n",
        "for string in corpus:\n",
        "    lst_words = string.split()\n",
        "    lst_grams = [\" \".join(lst_words[i:i+1]) for i in range(0, \n",
        "                 len(lst_words), 1)]\n",
        "    lst_corpus.append(lst_grams)\n",
        "    \n",
        "## detect common bigrams and trigrams using the fitted detectors\n",
        "lst_corpus = list(bigrams_detector[lst_corpus])\n",
        "lst_corpus = list(trigrams_detector[lst_corpus])\n",
        "## text to sequence with the fitted tokenizer\n",
        "lst_text2seq = tokenizer.texts_to_sequences(lst_corpus)\n",
        "\n",
        "## padding sequence\n",
        "X_test = kprocessing.sequence.pad_sequences(lst_text2seq, maxlen=15,\n",
        "             padding=\"post\", truncating=\"post\")"
      ],
      "metadata": {
        "id": "yfERPT7OUTKE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## start the matrix (length of vocabulary x vector size) with all 0s\n",
        "embeddings = np.zeros((len(dic_vocabulary)+1, 300))\n",
        "for word,idx in dic_vocabulary.items():\n",
        "    ## update the row with vector\n",
        "    try:\n",
        "        embeddings[idx] =  nlp[word]\n",
        "    ## if word not in model then skip and the row stays all 0s\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EReq4UIAUUSs",
        "outputId": "a12fb894-34e4-445d-af55-af1f27d2cb49"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"data\"\n",
        "print(\"dic[word]:\", dic_vocabulary[word], \"|idx\")\n",
        "print(\"embeddings[idx]:\", embeddings[dic_vocabulary[word]].shape, \n",
        "      \"|vector\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaJMJN1NUZMF",
        "outputId": "61ab29a0-d84f-43b7-d719-238df2f607f9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dic[word]: 370 |idx\n",
            "embeddings[idx]: (300,) |vector\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## code attention layer\n",
        "def attention_layer(inputs, neurons):\n",
        "    x = layers.Permute((2,1))(inputs)\n",
        "    x = layers.Dense(neurons, activation=\"softmax\")(x)\n",
        "    x = layers.Permute((2,1), name=\"attention\")(x)\n",
        "    x = layers.multiply([inputs, x])\n",
        "    return x\n",
        "\n",
        "## input\n",
        "x_in = layers.Input(shape=(15,))\n",
        "## embedding\n",
        "x = layers.Embedding(input_dim=embeddings.shape[0],  \n",
        "                     output_dim=embeddings.shape[1], \n",
        "                     weights=[embeddings],\n",
        "                     input_length=15, trainable=False)(x_in)\n",
        "## apply attention\n",
        "x = attention_layer(x, neurons=15)\n",
        "## 2 layers of bidirectional lstm\n",
        "x = layers.Bidirectional(layers.LSTM(units=15, dropout=0.2, \n",
        "                         return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(units=15, dropout=0.2))(x)\n",
        "## final dense layers\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "y_out = layers.Dense(3, activation='softmax')(x)\n",
        "## compile\n",
        "model = models.Model(x_in, y_out)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwaS9LTeUtm-",
        "outputId": "996fa529-8984-4436-b110-b7589f2625e9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 15)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 15, 300)      383100      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 300, 15)      0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 300, 15)      240         ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " attention (Permute)            (None, 15, 300)      0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 15, 300)      0           ['embedding[0][0]',              \n",
            "                                                                  'attention[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 15, 30)       37920       ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 30)          5520        ['bidirectional[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 64)           1984        ['bidirectional_1[0][0]']        \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 3)            195         ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 428,959\n",
            "Trainable params: 45,859\n",
            "Non-trainable params: 383,100\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## encode y\n",
        "dic_y_mapping = {n:label for n,label in \n",
        "                 enumerate(np.unique(y_train))}\n",
        "inverse_dic = {v:k for k,v in dic_y_mapping.items()}\n",
        "y_train = np.array([inverse_dic[y] for y in y_train])\n",
        "\n"
      ],
      "metadata": {
        "id": "08O_BczSUy3x"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## train\n",
        "training = model.fit(x=X_train, y=y_train, epochs = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VCdBx94kVhJl",
        "outputId": "573fcdc6-b3ae-4232-9d15-4b4813488b37"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-9f59ea38dec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1233, in inner\n      self.run()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1147, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n      user_expressions, allow_stdin,\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-24-7b1c76c0daeb>\", line 9, in <module>\n      validation_split=0.3)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 949, in compute_loss\n      y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1861, in sparse_categorical_crossentropy\n      y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5239, in sparse_categorical_crossentropy\n      labels=target, logits=output)\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of 11 which is outside the valid range of [0, 3).  Label values: 3 10 3 2 11 1 1 3 1 0 8 1 5 1 2 2 11 2 1 0 0 2 0 2 2 2 4 2 2 8 7 2\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_11220]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## plot loss and accuracy\n",
        "metrics = [k for k in training.history.keys() if (\"loss\" not in k) and (\"val\" not in k)]\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2, sharey=True)\n",
        "ax[0].set(title=\"Training\")\n",
        "ax11 = ax[0].twinx()\n",
        "ax[0].plot(training.history['loss'], color='black')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Loss', color='black')\n",
        "for metric in metrics:\n",
        "    ax11.plot(training.history[metric], label=metric)\n",
        "ax11.set_ylabel(\"Score\", color='steelblue')\n",
        "ax11.legend()\n",
        "ax[1].set(title=\"Validation\")\n",
        "ax22 = ax[1].twinx()\n",
        "ax[1].plot(training.history['val_loss'], color='black')\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].set_ylabel('Loss', color='black')\n",
        "for metric in metrics:\n",
        "     ax22.plot(training.history['val_'+metric], label=metric)\n",
        "ax22.set_ylabel(\"Score\", color=\"steelblue\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "RP8HFEmPW83g",
        "outputId": "743c9f12-e9e0-44e7-d13c-6f640c4b2cf5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-78ea6cc64cac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## plot loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"val\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtwinx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## test\n",
        "predicted_prob = model.predict(X_test)\n",
        "predicted = [dic_y_mapping[np.argmax(pred)] for pred in \n",
        "             predicted_prob]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDAkElrPVyBu",
        "outputId": "426bd0d9-e084-46b6-907b-3891b7974a52"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 58s 15ms/step\n"
          ]
        }
      ]
    }
  ]
}